# Frequently Asked Questions (FAQ)

Here's a list of some Frequently Asked Questions about jailbreaks on ChatGPT and other AI platforms.

<details>
<summary>What is a Jailbreak?</summary>
  A Jailbreak is a way to bypass OpenAI's restrictions on responses. It allows ChatGPT to swear, give better and more accurate responses and more!
</details>
